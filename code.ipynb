{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, data load, metric function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T01:37:34.554318Z",
     "start_time": "2022-03-22T01:37:34.552369Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import BallTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T01:37:34.979830Z",
     "start_time": "2022-03-22T01:37:34.965763Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.load('X_train_surge.npz')\n",
    "Y_train = pd.read_csv('Y_train_surge.csv')\n",
    "X_test = np.load('X_test_surge.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T01:37:38.336585Z",
     "start_time": "2022-03-22T01:37:35.582884Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_train_set(X, Y, val_size=0.2, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    nb_examples = len(Y)\n",
    "    val_examples = int(val_size * nb_examples)\n",
    "    \n",
    "    val_indices = rng.choice(nb_examples, size=val_examples, replace=False)\n",
    "    \n",
    "    train_indices = np.setdiff1d(\n",
    "        np.arange(nb_examples),\n",
    "        val_indices,\n",
    "        assume_unique=True\n",
    "    )\n",
    "    train_indices = rng.permutation(train_indices)\n",
    "    \n",
    "    X_train = {}\n",
    "    X_val = {}\n",
    "    for feat in X.files:\n",
    "        X_train[feat] = X[feat][train_indices]\n",
    "        X_val[feat] = X[feat][val_indices]\n",
    "    \n",
    "    return X_train, Y.iloc[train_indices], \\\n",
    "            X_val, Y.iloc[val_indices]\n",
    "\n",
    "X_train, Y_train, X_val, Y_val = split_train_set(X_train, Y_train, val_size=0.091, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T01:37:38.341156Z",
     "start_time": "2022-03-22T01:37:38.337683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_slp = X_train['t_slp'] / 3600\n",
    "t_slp_delta = t_slp - t_slp[:, 0].reshape(-1, 1)\n",
    "np.allclose(np.round(t_slp_delta), np.round(t_slp_delta)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T01:37:39.172548Z",
     "start_time": "2022-03-22T01:37:39.169529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T01:37:39.973322Z",
     "start_time": "2022-03-22T01:37:39.964890Z"
    }
   },
   "outputs": [],
   "source": [
    "SLP_HEIGHT = SLP_WIDTH = 41\n",
    "SLP_PER_EX = 40\n",
    "T_SURGE_NORMALISATION = 240.\n",
    "SLP_REL_TIMESTAMPS = np.arange(24*5, step=3) / T_SURGE_NORMALISATION\n",
    "\n",
    "\n",
    "def normalised_tensor(array, mean, std):\n",
    "        return torch.from_numpy((array - mean) / std)\n",
    "\n",
    "def preprocessing(X, slp_mean=None, slp_std=None, t_slp_mean=None, t_slp_std=None,\n",
    "                 surge_mean=None, surge_std=None):\n",
    "    slp = X['slp'].reshape(-1, SLP_PER_EX, SLP_HEIGHT, SLP_WIDTH)\n",
    "    slp = np.roll(slp, shift=-11, axis=3)\n",
    "    if slp_mean is None:\n",
    "        slp_mean = np.mean(slp)\n",
    "    if slp_std is None:\n",
    "        slp_std = np.std(slp)\n",
    "    slp = normalised_tensor(slp, slp_mean, slp_std)\n",
    "    \n",
    "    fst_slp = X['t_slp'][:, 0] / 3600\n",
    "    fst_slp_tmp = fst_slp.reshape(-1, 1)\n",
    "    \n",
    "    def rel_surge_time(index):\n",
    "        t_surge = X[index] / 3600\n",
    "        t_surge -= fst_slp_tmp\n",
    "        return torch.from_numpy(t_surge / T_SURGE_NORMALISATION)\n",
    "\n",
    "    t_surge1_in = rel_surge_time('t_surge1_input')\n",
    "    t_surge2_in = rel_surge_time('t_surge2_input')\n",
    "    t_surge1_out = rel_surge_time('t_surge1_output')\n",
    "    t_surge2_out = rel_surge_time('t_surge2_output')\n",
    "    \n",
    "    if t_slp_mean is None:\n",
    "        t_slp_mean = np.mean(fst_slp)\n",
    "    if t_slp_std is None:\n",
    "        t_slp_std = np.std(fst_slp)\n",
    "    fst_slp = normalised_tensor(fst_slp, t_slp_mean, t_slp_std)\n",
    "    \n",
    "    surge1 = X['surge1_input']\n",
    "    surge2 = X['surge2_input']\n",
    "    if surge_mean is None or surge_std is None:\n",
    "        surges = np.concatenate([surge1, surge2], axis=None)\n",
    "        surge_mean = np.mean(surges)\n",
    "        surge_std = np.std(surges)\n",
    "    surge1_in = normalised_tensor(surge1, surge_mean, surge_std)\n",
    "    surge2_in = normalised_tensor(surge2, surge_mean, surge_std)\n",
    "    \n",
    "    return X['id_sequence'], slp, slp_mean, slp_std, \\\n",
    "            fst_slp, t_slp_mean, t_slp_std, \\\n",
    "            t_surge1_in, t_surge2_in, t_surge1_out, t_surge2_out, \\\n",
    "            surge1_in, surge2_in, surge_mean, surge_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T01:37:43.399353Z",
     "start_time": "2022-03-22T01:37:41.856917Z"
    }
   },
   "outputs": [],
   "source": [
    "train_id_seq, train_slp, slp_mean, slp_std, \\\n",
    "train_fst_slp, t_slp_mean, t_slp_std, \\\n",
    "train_t_surge1_in, train_t_surge2_in, train_t_surge1_out, train_t_surge2_out, \\\n",
    "train_surge1_in, train_surge2_in, surge_mean, surge_std = preprocessing(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T01:37:43.466011Z",
     "start_time": "2022-03-22T01:37:43.400513Z"
    }
   },
   "outputs": [],
   "source": [
    "val_id_seq, val_slp, _, _, \\\n",
    "val_fst_slp, _, _, \\\n",
    "val_t_surge1_in, val_t_surge2_in, val_t_surge1_out, val_t_surge2_out, \\\n",
    "val_surge1_in, val_surge2_in, _, _ = preprocessing(X_val, slp_mean, slp_std, t_slp_mean, t_slp_std, surge_mean, surge_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T01:37:43.647091Z",
     "start_time": "2022-03-22T01:37:43.466978Z"
    }
   },
   "outputs": [],
   "source": [
    "test_id_seq, test_slp, _, _, \\\n",
    "test_fst_slp, _, _, \\\n",
    "test_t_surge1_in, test_t_surge2_in, test_t_surge1_out, test_t_surge2_out, \\\n",
    "test_surge1_in, test_surge2_in, _, _ = preprocessing(X_test, slp_mean, slp_std, t_slp_mean, t_slp_std, surge_mean, surge_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T01:37:54.066849Z",
     "start_time": "2022-03-22T01:37:54.062104Z"
    }
   },
   "outputs": [],
   "source": [
    "train_Y_id_seq = Y_train['id_sequence'].values\n",
    "assert np.alltrue(train_Y_id_seq == train_id_seq), 'Data/label index mismatch'\n",
    "\n",
    "train_surge1_out = Y_train.iloc[:, 1:11].values\n",
    "train_surge1_out = normalised_tensor(train_surge1_out, surge_mean, surge_std)\n",
    "train_surge2_out = Y_train.iloc[:, 11:].values\n",
    "train_surge2_out = normalised_tensor(train_surge2_out, surge_mean, surge_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T01:37:54.411551Z",
     "start_time": "2022-03-22T01:37:54.405485Z"
    }
   },
   "outputs": [],
   "source": [
    "val_Y_id_seq = Y_val['id_sequence'].values\n",
    "assert np.alltrue(val_Y_id_seq == val_id_seq), 'Data/label index mismatch'\n",
    "\n",
    "val_surge1_out = Y_val.iloc[:, 1:11].values\n",
    "val_surge1_out = normalised_tensor(val_surge1_out, surge_mean, surge_std)\n",
    "val_surge2_out = Y_val.iloc[:, 11:].values\n",
    "val_surge2_out = normalised_tensor(val_surge2_out, surge_mean, surge_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T01:47:00.727795Z",
     "start_time": "2022-03-22T01:47:00.718715Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "resnet_versions = {\n",
    "    18 : models.resnet18,\n",
    "    34 : models.resnet34,\n",
    "    50 : models.resnet50,\n",
    "}\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    train_slp,\n",
    "#     train_fst_slp,\n",
    "    train_t_surge1_in,\n",
    "    train_surge1_in,\n",
    "    train_t_surge2_in,\n",
    "    train_surge2_in,\n",
    "    train_t_surge1_out,\n",
    "    train_surge1_out,\n",
    "    train_t_surge2_out,\n",
    "    train_surge2_out,\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "val_dataset = TensorDataset(\n",
    "    val_slp,\n",
    "#     val_fst_slp,\n",
    "    val_t_surge1_in,\n",
    "    val_surge1_in,\n",
    "    val_t_surge2_in,\n",
    "    val_surge2_in,\n",
    "    val_t_surge1_out,\n",
    "    val_surge1_out,\n",
    "    val_t_surge2_out,\n",
    "    val_surge2_out,\n",
    ")\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    test_slp,\n",
    "#     test_fst_slp,\n",
    "    test_t_surge1_in,\n",
    "    test_surge1_in,\n",
    "    test_t_surge2_in,\n",
    "    test_surge2_in,\n",
    "    test_t_surge1_out,\n",
    "    test_t_surge2_out\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class Conv2d(nn.Conv2d):\n",
    "    \"\"\"Weight standardisation\n",
    "    (see https://arxiv.org/pdf/1903.10520.pdf and https://github.com/joe-siyuan-qiao/WeightStandardization)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(Conv2d, self).__init__(in_channels, out_channels, kernel_size, stride,\n",
    "                 padding, dilation, groups, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weight = self.weight\n",
    "        weight_mean = weight.mean(dim=1, keepdim=True).mean(dim=2,\n",
    "                                  keepdim=True).mean(dim=3, keepdim=True)\n",
    "        weight = weight - weight_mean\n",
    "        std = weight.view(weight.size(0), -1).std(dim=1).view(-1, 1, 1, 1) + 1e-5\n",
    "        weight = weight / std.expand_as(weight)\n",
    "        return F.conv2d(x, weight, self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, resnet_layers, out_features):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet_versions[resnet_layers]()\n",
    "        self.resnet.conv1 = nn.Conv2d(SLP_PER_EX, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "        # Change the number of out_features from 1000 to `out_features`\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, out_features)\n",
    "        self.slp_embed_size = out_features\n",
    "        self.fc1 = nn.Linear(20, 1)\n",
    "        self.fc2 = nn.Linear(20, 1)\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=out_features, num_layers=1, bias=True, batch_first=True, \\\n",
    "                            dropout=.2, bidirectional=False, proj_size=1)\n",
    "        # LSTM:\n",
    "        # Add prediction time?\n",
    "        # Learn to associate pressure_mapt to their timestamps\n",
    "        \n",
    "    def input_embedding(self, t_surge_in, surge_in):\n",
    "        surge = torch.cat([t_surge_in, surge_in], dim=1)\n",
    "        surge = torch.relu(self.fc1(surge))\n",
    "        surge = self.fc2(surge)\n",
    "        return surge\n",
    "        \n",
    "    def time_embedding(self, t_surge_out):\n",
    "        t_surge_out = torch.relu(self.fc3(t_surge_out))\n",
    "        t_surge_out = self.fc4(t_surge_out)\n",
    "        return t_surge_out\n",
    "        \n",
    "    def forward(self, slp, t_surge1_in, surge1_in, t_surge2_in, surge2_in, t_surge1_out, t_surge2_out):\n",
    "        cell = self.resnet(slp)\n",
    "        c_0 = torch.cat([cell, cell], dim=0).unsqueeze(0)\n",
    "        \n",
    "        surge1 = torch.cat([t_surge1_in, surge1_in], dim=1)\n",
    "        hidden1 = self.fc1(surge1)\n",
    "        surge2 = torch.cat([t_surge2_in, surge2_in], dim=1)\n",
    "        hidden2 = self.fc2(surge2)\n",
    "        h_0 = torch.cat([hidden1, hidden2], dim=0).unsqueeze(0)\n",
    "        \n",
    "        lstm_input = torch.cat([t_surge1_out, t_surge2_out], dim=0).unsqueeze(2)\n",
    "#         print(t_surge1_out.dtype, t_surge2_out.dtype, h_0.dtype, c_0.dtype)\n",
    "        output, _ = self.lstm(lstm_input, (h_0, c_0))\n",
    "        output = output.squeeze()\n",
    "        return output[:len(slp)], output[len(slp):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T01:47:01.039167Z",
     "start_time": "2022-03-22T01:47:01.024692Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_weights = torch.linspace(1, 0.1, 10, requires_grad=False).to(device)\n",
    "    \n",
    "def surge_prediction_metric(surge1_true, surge2_true, surge1_pred, surge2_pred):\n",
    "    surge1_score = torch.mean(torch.square(surge1_true - surge1_pred) * loss_weights)\n",
    "    surge2_score = torch.mean(torch.square(surge2_true - surge2_pred) * loss_weights)\n",
    "    return surge1_score + surge2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T01:47:01.456485Z",
     "start_time": "2022-03-22T01:47:01.446746Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optmiser, epochs):\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    \n",
    "    for epoch_num in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = []\n",
    "\n",
    "        for batch, (slp, t_surge1_in, surge1_in, t_surge2_in, surge2_in, t_surge1_out, surge1_out, t_surge2_out, surge2_out) in enumerate(train_dataloader):\n",
    "            slp = slp.to(device)\n",
    "            t_surge1_in = t_surge1_in.to(device)\n",
    "            surge1_in = surge1_in.to(device)\n",
    "            t_surge2_in = t_surge2_in.to(device)\n",
    "            surge2_in = surge2_in.to(device)\n",
    "            t_surge1_out = t_surge1_out.to(device)\n",
    "            surge1_out = surge1_out.to(device)\n",
    "            t_surge2_out = t_surge2_out.to(device)\n",
    "            surge2_out = surge2_out.to(device)\n",
    "            surge1_out_pred, surge2_out_pred = model(slp, t_surge1_in, surge1_in, t_surge2_in, surge2_in, t_surge1_out, t_surge2_out)\n",
    "            \n",
    "            loss = loss_fn(surge1_out, surge2_out, surge1_out_pred, surge2_out_pred)\n",
    "            running_loss.append(loss.item())\n",
    "            \n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "        epoch_loss = np.mean(running_loss)\n",
    "        train_loss.append(epoch_loss)\n",
    "        print(f'Epoch {epoch_num+1:03d} | Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        if epoch_num % 5 == 0:\n",
    "            val_loss = evaluate(model, loss_fn)\n",
    "            print(f'\\tVal loss: {val_loss:.4f}')\n",
    "        \n",
    "    return train_loss\n",
    "\n",
    "def evaluate(model, loss_fn):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        losses = []\n",
    "        for slp, t_surge1_in, surge1_in, t_surge2_in, surge2_in, t_surge1_out, surge1_out, t_surge2_out, surge2_out in val_dataloader:\n",
    "            slp = slp.to(device)\n",
    "            t_surge1_in = t_surge1_in.to(device)\n",
    "            surge1_in = surge1_in.to(device)\n",
    "            t_surge2_in = t_surge2_in.to(device)\n",
    "            surge2_in = surge2_in.to(device)\n",
    "            t_surge1_out = t_surge1_out.to(device)\n",
    "            surge1_out = surge1_out.to(device)\n",
    "            t_surge2_out = t_surge2_out.to(device)\n",
    "            surge2_out = surge2_out.to(device)\n",
    "            surge1_out_pred, surge2_out_pred = model(slp, t_surge1_in, surge1_in, t_surge2_in, surge2_in, t_surge1_out, t_surge2_out)\n",
    "            \n",
    "            loss = loss_fn(surge1_out, surge2_out, surge1_out_pred, surge2_out_pred)\n",
    "            losses.append(loss.item())\n",
    "        return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T01:49:13.998570Z",
     "start_time": "2022-03-22T01:47:02.009113Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angelo/anaconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss: 0.9978\n",
      "\tVal loss: 0.8991\n",
      "Epoch 002 | Loss: 0.8588\n",
      "Epoch 003 | Loss: 0.6985\n",
      "Epoch 004 | Loss: 0.6546\n",
      "Epoch 005 | Loss: 0.6288\n",
      "Epoch 006 | Loss: 0.6086\n",
      "\tVal loss: 0.5826\n",
      "Epoch 007 | Loss: 0.5897\n",
      "Epoch 008 | Loss: 0.5701\n",
      "Epoch 009 | Loss: 0.5499\n",
      "Epoch 010 | Loss: 0.5341\n",
      "Epoch 011 | Loss: 0.5206\n",
      "\tVal loss: 0.5395\n",
      "Epoch 012 | Loss: 0.5090\n",
      "Epoch 013 | Loss: 0.4914\n",
      "Epoch 014 | Loss: 0.4784\n",
      "Epoch 015 | Loss: 0.4724\n",
      "Epoch 016 | Loss: 0.4672\n",
      "\tVal loss: 0.5381\n",
      "Epoch 017 | Loss: 0.4623\n",
      "Epoch 018 | Loss: 0.4613\n",
      "Epoch 019 | Loss: 0.4568\n",
      "Epoch 020 | Loss: 0.4430\n",
      "Epoch 021 | Loss: 0.4291\n",
      "\tVal loss: 0.6112\n",
      "Epoch 022 | Loss: 0.4239\n",
      "Epoch 023 | Loss: 0.4131\n",
      "Epoch 024 | Loss: 0.3981\n",
      "Epoch 025 | Loss: 0.3832\n",
      "Epoch 026 | Loss: 0.3788\n",
      "\tVal loss: 0.5530\n",
      "Epoch 027 | Loss: 0.3813\n",
      "Epoch 028 | Loss: 0.3834\n",
      "Epoch 029 | Loss: 0.3817\n",
      "Epoch 030 | Loss: 0.3791\n",
      "Epoch 031 | Loss: 0.3780\n",
      "\tVal loss: 0.5594\n",
      "Epoch 032 | Loss: 0.3795\n",
      "Epoch 033 | Loss: 0.3690\n",
      "Epoch 034 | Loss: 0.3496\n",
      "Epoch 035 | Loss: 0.3297\n",
      "Epoch 036 | Loss: 0.3230\n",
      "\tVal loss: 0.5452\n",
      "Epoch 037 | Loss: 0.3256\n",
      "Epoch 038 | Loss: 0.3338\n",
      "Epoch 039 | Loss: 0.3345\n",
      "Epoch 040 | Loss: 0.3354\n",
      "Epoch 041 | Loss: 0.3245\n",
      "\tVal loss: 0.5436\n",
      "Epoch 042 | Loss: 0.3175\n",
      "Epoch 043 | Loss: 0.3162\n",
      "Epoch 044 | Loss: 0.3107\n",
      "Epoch 045 | Loss: 0.3126\n",
      "Epoch 046 | Loss: 0.3126\n",
      "\tVal loss: 0.5821\n",
      "Epoch 047 | Loss: 0.3185\n",
      "Epoch 048 | Loss: 0.3234\n",
      "Epoch 049 | Loss: 0.3437\n",
      "Epoch 050 | Loss: 0.3543\n",
      "Epoch 051 | Loss: 0.3230\n",
      "\tVal loss: 0.5661\n",
      "Epoch 052 | Loss: 0.2918\n",
      "Epoch 053 | Loss: 0.2754\n",
      "Epoch 054 | Loss: 0.2717\n",
      "Epoch 055 | Loss: 0.2778\n",
      "Epoch 056 | Loss: 0.2895\n",
      "\tVal loss: 0.5716\n",
      "Epoch 057 | Loss: 0.3061\n",
      "Epoch 058 | Loss: 0.3166\n",
      "Epoch 059 | Loss: 0.3069\n",
      "Epoch 060 | Loss: 0.2895\n",
      "Epoch 061 | Loss: 0.2789\n",
      "\tVal loss: 0.5817\n",
      "Epoch 062 | Loss: 0.2729\n",
      "Epoch 063 | Loss: 0.2709\n",
      "Epoch 064 | Loss: 0.2726\n",
      "Epoch 065 | Loss: 0.2811\n",
      "Epoch 066 | Loss: 0.2865\n",
      "\tVal loss: 0.6100\n",
      "Epoch 067 | Loss: 0.2845\n",
      "Epoch 068 | Loss: 0.2823\n",
      "Epoch 069 | Loss: 0.2775\n",
      "Epoch 070 | Loss: 0.2685\n",
      "Epoch 071 | Loss: 0.2612\n",
      "\tVal loss: 0.5905\n",
      "Epoch 072 | Loss: 0.2581\n",
      "Epoch 073 | Loss: 0.2611\n",
      "Epoch 074 | Loss: 0.2635\n",
      "Epoch 075 | Loss: 0.2700\n",
      "Epoch 076 | Loss: 0.2771\n",
      "\tVal loss: 0.5831\n",
      "Epoch 077 | Loss: 0.2728\n",
      "Epoch 078 | Loss: 0.2742\n",
      "Epoch 079 | Loss: 0.2722\n",
      "Epoch 080 | Loss: 0.2759\n",
      "Epoch 081 | Loss: 0.2898\n",
      "\tVal loss: 0.6818\n",
      "Epoch 082 | Loss: 0.3206\n",
      "Epoch 083 | Loss: 0.3523\n",
      "Epoch 084 | Loss: 0.3238\n",
      "Epoch 085 | Loss: 0.2818\n",
      "Epoch 086 | Loss: 0.2525\n",
      "\tVal loss: 0.5496\n",
      "Epoch 087 | Loss: 0.2369\n",
      "Epoch 088 | Loss: 0.2302\n",
      "Epoch 089 | Loss: 0.2292\n",
      "Epoch 090 | Loss: 0.2349\n",
      "Epoch 091 | Loss: 0.2453\n",
      "\tVal loss: 0.5821\n",
      "Epoch 092 | Loss: 0.2515\n",
      "Epoch 093 | Loss: 0.2573\n",
      "Epoch 094 | Loss: 0.2749\n",
      "Epoch 095 | Loss: 0.3031\n",
      "Epoch 096 | Loss: 0.3068\n",
      "\tVal loss: 0.6043\n",
      "Epoch 097 | Loss: 0.2749\n",
      "Epoch 098 | Loss: 0.2544\n",
      "Epoch 099 | Loss: 0.2390\n",
      "Epoch 100 | Loss: 0.2302\n"
     ]
    }
   ],
   "source": [
    "model = Network(18, 100).to(device)\n",
    "optimiser = optim.Adam(model.parameters())\n",
    "_ = train(model, surge_prediction_metric, optimiser, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T02:06:55.371435Z",
     "start_time": "2022-03-22T02:06:55.367458Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_submission(model, fn='submission.csv'):\n",
    "    COLUMNS = [\n",
    "        'surge1_t0', 'surge1_t1', 'surge1_t2', 'surge1_t3', 'surge1_t4',\n",
    "        'surge1_t5', 'surge1_t6', 'surge1_t7', 'surge1_t8', 'surge1_t9',\n",
    "        'surge2_t0', 'surge2_t1', 'surge2_t2', 'surge2_t3', 'surge2_t4',\n",
    "        'surge2_t5', 'surge2_t6', 'surge2_t7', 'surge2_t8', 'surge2_t9' ]\n",
    "    surge1_output = []\n",
    "    surge2_output = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for slp, t_surge1_in, surge1_in, t_surge2_in, surge2_in, t_surge1_out, t_surge2_out in test_dataloader:\n",
    "            slp = slp.to(device)\n",
    "            t_surge1_in = t_surge1_in.to(device)\n",
    "            surge1_in = surge1_in.to(device)\n",
    "            t_surge2_in = t_surge2_in.to(device)\n",
    "            surge2_in = surge2_in.to(device)\n",
    "            t_surge1_out = t_surge1_out.to(device)\n",
    "            t_surge2_out = t_surge2_out.to(device)\n",
    "            surge1_out_pred, surge2_out_pred = model(slp, t_surge1_in, surge1_in, t_surge2_in, surge2_in, t_surge1_out, t_surge2_out)\n",
    "            surge1_output.append(surge1_out_pred)\n",
    "            surge2_output.append(surge2_out_pred)\n",
    "\n",
    "    surge1_output = torch.cat(surge1_output, dim=0)\n",
    "    surge2_output = torch.cat(surge2_output, dim=0)\n",
    "    test_outputs = torch.cat([surge1_output, surge2_output], dim=1).detach().cpu().numpy()\n",
    "\n",
    "    test_df = pd.DataFrame(test_outputs, index=test_id_seq, columns=COLUMNS)\n",
    "    test_df.index.name = 'id_sequence'\n",
    "    test_df.to_csv(fn)\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T02:06:58.061936Z",
     "start_time": "2022-03-22T02:06:57.992001Z"
    }
   },
   "outputs": [],
   "source": [
    "df = write_submission(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T02:06:05.809337Z",
     "start_time": "2022-03-22T02:06:05.789324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surge1_t0</th>\n",
       "      <th>surge1_t1</th>\n",
       "      <th>surge1_t2</th>\n",
       "      <th>surge1_t3</th>\n",
       "      <th>surge1_t4</th>\n",
       "      <th>surge1_t5</th>\n",
       "      <th>surge1_t6</th>\n",
       "      <th>surge1_t7</th>\n",
       "      <th>surge1_t8</th>\n",
       "      <th>surge1_t9</th>\n",
       "      <th>surge2_t0</th>\n",
       "      <th>surge2_t1</th>\n",
       "      <th>surge2_t2</th>\n",
       "      <th>surge2_t3</th>\n",
       "      <th>surge2_t4</th>\n",
       "      <th>surge2_t5</th>\n",
       "      <th>surge2_t6</th>\n",
       "      <th>surge2_t7</th>\n",
       "      <th>surge2_t8</th>\n",
       "      <th>surge2_t9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_sequence</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5600</th>\n",
       "      <td>-1.522672</td>\n",
       "      <td>-1.640056</td>\n",
       "      <td>-1.812372</td>\n",
       "      <td>-1.873276</td>\n",
       "      <td>-1.911106</td>\n",
       "      <td>-1.892778</td>\n",
       "      <td>-1.814209</td>\n",
       "      <td>-1.698588</td>\n",
       "      <td>-1.570127</td>\n",
       "      <td>-1.445986</td>\n",
       "      <td>-1.077388</td>\n",
       "      <td>-1.206931</td>\n",
       "      <td>-1.322765</td>\n",
       "      <td>-1.355515</td>\n",
       "      <td>-1.416860</td>\n",
       "      <td>-1.485878</td>\n",
       "      <td>-1.503089</td>\n",
       "      <td>-1.474643</td>\n",
       "      <td>-1.412876</td>\n",
       "      <td>-1.315216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5601</th>\n",
       "      <td>-0.172018</td>\n",
       "      <td>-0.244204</td>\n",
       "      <td>-0.333128</td>\n",
       "      <td>-0.247466</td>\n",
       "      <td>0.008339</td>\n",
       "      <td>0.311038</td>\n",
       "      <td>0.669055</td>\n",
       "      <td>1.009192</td>\n",
       "      <td>1.198229</td>\n",
       "      <td>1.189028</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>-0.052519</td>\n",
       "      <td>-0.104194</td>\n",
       "      <td>-0.077168</td>\n",
       "      <td>0.124576</td>\n",
       "      <td>0.411364</td>\n",
       "      <td>0.781786</td>\n",
       "      <td>1.110761</td>\n",
       "      <td>1.277642</td>\n",
       "      <td>1.251851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>-0.728413</td>\n",
       "      <td>-1.103798</td>\n",
       "      <td>-1.081307</td>\n",
       "      <td>-0.869735</td>\n",
       "      <td>-0.684275</td>\n",
       "      <td>-0.531688</td>\n",
       "      <td>-0.410095</td>\n",
       "      <td>-0.311700</td>\n",
       "      <td>-0.223303</td>\n",
       "      <td>-0.145472</td>\n",
       "      <td>1.353438</td>\n",
       "      <td>1.628443</td>\n",
       "      <td>1.170808</td>\n",
       "      <td>0.442155</td>\n",
       "      <td>0.039545</td>\n",
       "      <td>-0.142167</td>\n",
       "      <td>-0.216019</td>\n",
       "      <td>-0.203616</td>\n",
       "      <td>-0.161684</td>\n",
       "      <td>-0.113963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5603</th>\n",
       "      <td>-0.214031</td>\n",
       "      <td>0.022230</td>\n",
       "      <td>0.161170</td>\n",
       "      <td>0.047790</td>\n",
       "      <td>-0.173768</td>\n",
       "      <td>-0.312626</td>\n",
       "      <td>-0.312222</td>\n",
       "      <td>-0.243562</td>\n",
       "      <td>-0.164647</td>\n",
       "      <td>-0.095614</td>\n",
       "      <td>1.032095</td>\n",
       "      <td>1.588513</td>\n",
       "      <td>1.518492</td>\n",
       "      <td>0.934075</td>\n",
       "      <td>0.517910</td>\n",
       "      <td>0.386632</td>\n",
       "      <td>0.364263</td>\n",
       "      <td>0.341955</td>\n",
       "      <td>0.313909</td>\n",
       "      <td>0.286394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5604</th>\n",
       "      <td>0.188806</td>\n",
       "      <td>0.256014</td>\n",
       "      <td>0.136325</td>\n",
       "      <td>-0.055788</td>\n",
       "      <td>-0.255821</td>\n",
       "      <td>-0.438868</td>\n",
       "      <td>-0.531611</td>\n",
       "      <td>-0.504565</td>\n",
       "      <td>-0.409072</td>\n",
       "      <td>-0.300028</td>\n",
       "      <td>-0.038583</td>\n",
       "      <td>0.077969</td>\n",
       "      <td>-0.076706</td>\n",
       "      <td>-0.310813</td>\n",
       "      <td>-0.561307</td>\n",
       "      <td>-0.757425</td>\n",
       "      <td>-0.837745</td>\n",
       "      <td>-0.798326</td>\n",
       "      <td>-0.687479</td>\n",
       "      <td>-0.554552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6104</th>\n",
       "      <td>-0.202868</td>\n",
       "      <td>-0.458387</td>\n",
       "      <td>-0.676621</td>\n",
       "      <td>-0.850127</td>\n",
       "      <td>-0.801504</td>\n",
       "      <td>-0.661781</td>\n",
       "      <td>-0.550004</td>\n",
       "      <td>-0.469796</td>\n",
       "      <td>-0.375337</td>\n",
       "      <td>-0.267382</td>\n",
       "      <td>0.679106</td>\n",
       "      <td>-0.081019</td>\n",
       "      <td>-0.426764</td>\n",
       "      <td>-0.630051</td>\n",
       "      <td>-0.645582</td>\n",
       "      <td>-0.500996</td>\n",
       "      <td>-0.302407</td>\n",
       "      <td>-0.138851</td>\n",
       "      <td>-0.036838</td>\n",
       "      <td>0.022590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6105</th>\n",
       "      <td>0.004178</td>\n",
       "      <td>-0.027268</td>\n",
       "      <td>-0.104875</td>\n",
       "      <td>-0.129565</td>\n",
       "      <td>-0.042405</td>\n",
       "      <td>0.124772</td>\n",
       "      <td>0.274499</td>\n",
       "      <td>0.309280</td>\n",
       "      <td>0.270955</td>\n",
       "      <td>0.226377</td>\n",
       "      <td>0.155758</td>\n",
       "      <td>-0.343349</td>\n",
       "      <td>-0.494503</td>\n",
       "      <td>-0.406895</td>\n",
       "      <td>-0.211891</td>\n",
       "      <td>0.009162</td>\n",
       "      <td>0.194007</td>\n",
       "      <td>0.265217</td>\n",
       "      <td>0.251194</td>\n",
       "      <td>0.218806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6106</th>\n",
       "      <td>-0.429599</td>\n",
       "      <td>-0.720932</td>\n",
       "      <td>-0.728523</td>\n",
       "      <td>-0.629140</td>\n",
       "      <td>-0.443044</td>\n",
       "      <td>-0.221718</td>\n",
       "      <td>0.056978</td>\n",
       "      <td>0.360464</td>\n",
       "      <td>0.566990</td>\n",
       "      <td>0.590129</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>-0.308064</td>\n",
       "      <td>-0.262538</td>\n",
       "      <td>-0.246235</td>\n",
       "      <td>-0.120654</td>\n",
       "      <td>0.120976</td>\n",
       "      <td>0.452356</td>\n",
       "      <td>0.784378</td>\n",
       "      <td>0.954932</td>\n",
       "      <td>0.906470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6107</th>\n",
       "      <td>0.218414</td>\n",
       "      <td>-0.065912</td>\n",
       "      <td>-0.073831</td>\n",
       "      <td>-0.228745</td>\n",
       "      <td>-0.546522</td>\n",
       "      <td>-0.754496</td>\n",
       "      <td>-0.782437</td>\n",
       "      <td>-0.702246</td>\n",
       "      <td>-0.584819</td>\n",
       "      <td>-0.462281</td>\n",
       "      <td>0.360878</td>\n",
       "      <td>-0.268439</td>\n",
       "      <td>-0.302901</td>\n",
       "      <td>-0.340486</td>\n",
       "      <td>-0.570672</td>\n",
       "      <td>-0.755228</td>\n",
       "      <td>-0.782008</td>\n",
       "      <td>-0.705261</td>\n",
       "      <td>-0.590581</td>\n",
       "      <td>-0.468862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>-0.082970</td>\n",
       "      <td>-0.123427</td>\n",
       "      <td>0.101262</td>\n",
       "      <td>0.405648</td>\n",
       "      <td>0.578660</td>\n",
       "      <td>0.476890</td>\n",
       "      <td>0.271017</td>\n",
       "      <td>0.211466</td>\n",
       "      <td>0.257518</td>\n",
       "      <td>0.282207</td>\n",
       "      <td>0.226513</td>\n",
       "      <td>-0.025818</td>\n",
       "      <td>0.269845</td>\n",
       "      <td>0.735363</td>\n",
       "      <td>1.123745</td>\n",
       "      <td>1.118167</td>\n",
       "      <td>0.872491</td>\n",
       "      <td>0.779338</td>\n",
       "      <td>0.723321</td>\n",
       "      <td>0.621802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             surge1_t0  surge1_t1  surge1_t2  surge1_t3  surge1_t4  surge1_t5  \\\n",
       "id_sequence                                                                     \n",
       "5600         -1.522672  -1.640056  -1.812372  -1.873276  -1.911106  -1.892778   \n",
       "5601         -0.172018  -0.244204  -0.333128  -0.247466   0.008339   0.311038   \n",
       "5602         -0.728413  -1.103798  -1.081307  -0.869735  -0.684275  -0.531688   \n",
       "5603         -0.214031   0.022230   0.161170   0.047790  -0.173768  -0.312626   \n",
       "5604          0.188806   0.256014   0.136325  -0.055788  -0.255821  -0.438868   \n",
       "...                ...        ...        ...        ...        ...        ...   \n",
       "6104         -0.202868  -0.458387  -0.676621  -0.850127  -0.801504  -0.661781   \n",
       "6105          0.004178  -0.027268  -0.104875  -0.129565  -0.042405   0.124772   \n",
       "6106         -0.429599  -0.720932  -0.728523  -0.629140  -0.443044  -0.221718   \n",
       "6107          0.218414  -0.065912  -0.073831  -0.228745  -0.546522  -0.754496   \n",
       "6108         -0.082970  -0.123427   0.101262   0.405648   0.578660   0.476890   \n",
       "\n",
       "             surge1_t6  surge1_t7  surge1_t8  surge1_t9  surge2_t0  surge2_t1  \\\n",
       "id_sequence                                                                     \n",
       "5600         -1.814209  -1.698588  -1.570127  -1.445986  -1.077388  -1.206931   \n",
       "5601          0.669055   1.009192   1.198229   1.189028   0.016760  -0.052519   \n",
       "5602         -0.410095  -0.311700  -0.223303  -0.145472   1.353438   1.628443   \n",
       "5603         -0.312222  -0.243562  -0.164647  -0.095614   1.032095   1.588513   \n",
       "5604         -0.531611  -0.504565  -0.409072  -0.300028  -0.038583   0.077969   \n",
       "...                ...        ...        ...        ...        ...        ...   \n",
       "6104         -0.550004  -0.469796  -0.375337  -0.267382   0.679106  -0.081019   \n",
       "6105          0.274499   0.309280   0.270955   0.226377   0.155758  -0.343349   \n",
       "6106          0.056978   0.360464   0.566990   0.590129   0.005821  -0.308064   \n",
       "6107         -0.782437  -0.702246  -0.584819  -0.462281   0.360878  -0.268439   \n",
       "6108          0.271017   0.211466   0.257518   0.282207   0.226513  -0.025818   \n",
       "\n",
       "             surge2_t2  surge2_t3  surge2_t4  surge2_t5  surge2_t6  surge2_t7  \\\n",
       "id_sequence                                                                     \n",
       "5600         -1.322765  -1.355515  -1.416860  -1.485878  -1.503089  -1.474643   \n",
       "5601         -0.104194  -0.077168   0.124576   0.411364   0.781786   1.110761   \n",
       "5602          1.170808   0.442155   0.039545  -0.142167  -0.216019  -0.203616   \n",
       "5603          1.518492   0.934075   0.517910   0.386632   0.364263   0.341955   \n",
       "5604         -0.076706  -0.310813  -0.561307  -0.757425  -0.837745  -0.798326   \n",
       "...                ...        ...        ...        ...        ...        ...   \n",
       "6104         -0.426764  -0.630051  -0.645582  -0.500996  -0.302407  -0.138851   \n",
       "6105         -0.494503  -0.406895  -0.211891   0.009162   0.194007   0.265217   \n",
       "6106         -0.262538  -0.246235  -0.120654   0.120976   0.452356   0.784378   \n",
       "6107         -0.302901  -0.340486  -0.570672  -0.755228  -0.782008  -0.705261   \n",
       "6108          0.269845   0.735363   1.123745   1.118167   0.872491   0.779338   \n",
       "\n",
       "             surge2_t8  surge2_t9  \n",
       "id_sequence                        \n",
       "5600         -1.412876  -1.315216  \n",
       "5601          1.277642   1.251851  \n",
       "5602         -0.161684  -0.113963  \n",
       "5603          0.313909   0.286394  \n",
       "5604         -0.687479  -0.554552  \n",
       "...                ...        ...  \n",
       "6104         -0.036838   0.022590  \n",
       "6105          0.251194   0.218806  \n",
       "6106          0.954932   0.906470  \n",
       "6107         -0.590581  -0.468862  \n",
       "6108          0.723321   0.621802  \n",
       "\n",
       "[509 rows x 20 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "Train using kNN of pressure fields at two instants in time, with 40 neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surge_prediction_metric(dataframe_y_true, dataframe_y_pred):\n",
    "    weights = np.linspace(1, 0.1, 10)[np.newaxis]\n",
    "    surge1_columns = [\n",
    "        'surge1_t0', 'surge1_t1', 'surge1_t2', 'surge1_t3', 'surge1_t4',\n",
    "        'surge1_t5', 'surge1_t6', 'surge1_t7', 'surge1_t8', 'surge1_t9' ]\n",
    "    surge2_columns = [\n",
    "        'surge2_t0', 'surge2_t1', 'surge2_t2', 'surge2_t3', 'surge2_t4',\n",
    "        'surge2_t5', 'surge2_t6', 'surge2_t7', 'surge2_t8', 'surge2_t9' ]\n",
    "    surge1_score = (weights * (dataframe_y_true[surge1_columns].values - dataframe_y_pred[surge1_columns].values)**2).mean()\n",
    "    surge2_score = (weights * (dataframe_y_true[surge2_columns].values - dataframe_y_pred[surge2_columns].values)**2).mean()\n",
    "\n",
    "    return surge1_score + surge2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfields = 2; time_step_slp = 8\n",
    "slp_train = []\n",
    "slp_all = X_train['slp']\n",
    "for i in range(5559):\n",
    "    slp_train.append(np.ndarray.flatten(slp_all[i,-1]))\n",
    "    for j in range(1,nfields):\n",
    "        slp_train[-1] = np.concatenate( ( slp_train[-1], np.ndarray.flatten(slp_all[i,-1-j*time_step_slp]) ) )\n",
    "slp_train = np.array(slp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "slp_test = []\n",
    "slp_all_test = X_test['slp']\n",
    "for i in range(509):\n",
    "    slp_test.append(np.ndarray.flatten(slp_all_test[i,-1]))\n",
    "    for j in range(1,nfields):\n",
    "        slp_test[-1] = np.concatenate( ( slp_test[-1], np.ndarray.flatten(slp_all_test[i,-1-j*time_step_slp]) ) )\n",
    "slp_test = np.array(slp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = BallTree(slp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "surge_test_benchmark = []; k = 40\n",
    "for i in range(509):\n",
    "    dist, ind = tree.query([slp_test[i]], k=k)\n",
    "    surge_test_benchmark.append(np.mean(surge_train[ind[0]], axis=0))\n",
    "surge_test_benchmark = np.array(surge_test_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_columns = [f'surge1_t{i}' for i in range(10)] + [f'surge2_t{i}' for i in range(10)]\n",
    "y_test_benchmark = pd.DataFrame(data=surge_test_benchmark, columns=y_columns, index=X_test['id_sequence'])\n",
    "y_test_benchmark.to_csv('Y_test_benchmark.csv', index_label='id_sequence', sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
